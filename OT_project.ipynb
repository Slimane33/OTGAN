{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OT_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIK2SCBi75dB",
        "colab_type": "text"
      },
      "source": [
        "# Optimal Transport Project\n",
        "\n",
        "*Authors : Romain Avouac, Slimane Thabet*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh69TJHokAUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from multiprocessing import cpu_count\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms.functional import to_pil_image, resize, to_tensor\n",
        "from torchvision.transforms.functional import normalize\n",
        "import imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJiJ2yhQRzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU configuration\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt9mVG5lIP6g",
        "colab_type": "text"
      },
      "source": [
        "## Load and preprocess MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82GY1zvRANnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(batch_size=128, img_size=28):\n",
        "    \"\"\"Download, preprocess and load MNIST data.\"\"\"\n",
        "    mnist = datasets.MNIST('data', train=True, download=True).data\n",
        "    # Perform transformation directly on raw data rather than in the DataLoader\n",
        "    # => avoids overhead of transforming at each batch call => much faster epochs.\n",
        "    pics = []\n",
        "    for pic in mnist:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size) # Resize image if needed\n",
        "        pic = to_tensor(pic)\n",
        "        pic = normalize(pic, 0.5, 0.5) # Normalize in [-1,1]\n",
        "        pics.append(pic)\n",
        "\n",
        "    mnist = torch.stack(pics)\n",
        "\n",
        "    return torch.utils.data.DataLoader(mnist, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lpuc57xkX7x",
        "colab_type": "text"
      },
      "source": [
        "## Vanilla GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axC1hgE-kZDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANGenerator(nn.Module):\n",
        "    def __init__(self, input_size, d, output_shape):\n",
        "        super(GANGenerator, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d*2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d*4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, \n",
        "                              output_shape[0] * output_shape[1] * output_shape[2])\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.map1(x))\n",
        "        x = self.act(self.map2(x))\n",
        "        x = self.act(self.map3(x))\n",
        "        x = torch.tanh(self.map4(x))\n",
        "        \n",
        "        return x.view((-1,)+self.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StPNp6QHkcFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANCritic(nn.Module):\n",
        "    def __init__(self, input_size, d):\n",
        "        super(GANCritic, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d//2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d//4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, 1)\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.act(self.map1(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map2(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map3(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = torch.sigmoid(self.map4(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5siAOXTkd8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN():\n",
        "    \n",
        "    def __init__(self, dataloader, generator, critic, lr=0.0001):\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        # default parameters for mnist \n",
        "        self.img_channels = dataloader.dataset[0].shape[0]\n",
        "        self.img_rows = dataloader.dataset[0].shape[1]\n",
        "        self.img_cols = dataloader.dataset[0].shape[2]\n",
        "        self.img_shape = (self.img_channels, self.img_rows, self.img_cols)\n",
        "        self.z_dim = z_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        self.generator = generator.to(device)\n",
        "        self.critic = critic.to(device)\n",
        "\n",
        "        \n",
        "    def sample_data(self, n_sample):\n",
        "        z_random = np.random.randn(n_sample, self.z_dim)\n",
        "        z_random = torch.FloatTensor(z_random).to(device)\n",
        "        samples = self.generator(z_random)\n",
        "        samples = samples.detach().cpu().numpy()\n",
        "        return samples\n",
        "        \n",
        "    def train(self, epochs=100, print_interval=10, save_generator_path=None):\n",
        "        \n",
        "        criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
        "        d_optimizer = optim.Adam(self.critic.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
        "        g_optimizer = optim.Adam(self.generator.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
        "        d_steps = 1\n",
        "        g_steps = 1\n",
        "\n",
        "        t = time()\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            for batch in self.dataloader:\n",
        "                batch = batch.type(torch.FloatTensor).to(device)\n",
        "\n",
        "                for d_index in range(d_steps):\n",
        "                    # 1. Train D on real+fake\n",
        "                    self.critic.zero_grad()\n",
        "\n",
        "                    #  1A: Train D on real\n",
        "                    d_real_data = Variable(batch.to(device))\n",
        "                    d_real_decision = self.critic(d_real_data)\n",
        "                    y_real = Variable(torch.ones(d_real_decision.shape).to(device))\n",
        "                    d_real_error = criterion(d_real_decision, y_real)\n",
        "        \n",
        "                    #  1B: Train D on fake\n",
        "                    d_gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    d_gen_input = Variable(d_gen_input.to(device))\n",
        "                    d_fake_data = self.generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "                    d_fake_decision = self.critic(d_fake_data)\n",
        "                    y_fake = Variable(torch.zeros(d_real_decision.shape).to(device))\n",
        "                    d_fake_error = criterion(d_fake_decision, y_fake) \n",
        "\n",
        "                    # Backward propagation on the sum of the two losses\n",
        "                    d_train_loss = d_real_error + d_fake_error\n",
        "                    d_train_loss.backward()\n",
        "                    d_optimizer.step() # Only optimizes D's parameters\n",
        "        \n",
        "                for g_index in range(g_steps):\n",
        "                    # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "                    self.generator.zero_grad()\n",
        "        \n",
        "                    gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    gen_input = Variable(gen_input.to(device))\n",
        "                    g_fake_data = self.generator(gen_input)\n",
        "                    dg_fake_decision = self.critic(g_fake_data)\n",
        "                    y_ones = Variable(torch.ones(dg_fake_decision.shape).to(device))\n",
        "                    g_error = criterion(dg_fake_decision, y_ones)   # Train G to pretend it's genuine\n",
        "        \n",
        "                    g_error.backward()\n",
        "                    g_optimizer.step()  # Only optimizes G's parameters\n",
        "                    \n",
        "    \n",
        "            if (epoch > 0 and epoch % print_interval == 0) or epoch+1 == epochs:\n",
        "                de = d_train_loss.detach().cpu().numpy()\n",
        "                ge = g_error.detach().cpu().numpy()\n",
        "                print(\"Epoch %s: C_loss =  %s ;  G_loss = %s;  time = %s\" %\n",
        "                      (epoch, de, ge, time()-t))\n",
        "                \n",
        "            # if epoch % 1 == 0:\n",
        "            #     samples = self.sample_data(3)*0.5 + 0.5\n",
        "            #     for img in samples:\n",
        "            #         plt.figure()\n",
        "            #         plt.imshow(img[0,:,:], cmap='gray')\n",
        "            #         plt.show()\n",
        "\n",
        "        if save_generator_path is not None:\n",
        "            torch.save(self.generator.state_dict(), save_generator_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTA9jZhVB6Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vanilla GAN parameters\n",
        "img_size = 28 # Keep initial MNIST size\n",
        "z_dim = 100\n",
        "G_dim_init = 128\n",
        "C_dim_init = 1024\n",
        "\n",
        "lr = 0.0002\n",
        "batch_size = 128\n",
        "n_epochs = 100\n",
        "\n",
        "save_generator_path = 'vanilla_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uivUpAPfBMR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size)\n",
        "img_shape = mnist_dataloader.dataset[0].shape\n",
        "n_pixels = img_shape[0] * img_shape[1] * img_shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-GlOy3aCn9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5353fe9-22a0-48e2-d857-5dc04c1d25a0"
      },
      "source": [
        "TRAIN_MODE = False\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init)\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)\n",
        "    gan.train(n_epochs, save_generator_path=save_generator_path,\n",
        "              print_interval=10) # Change `save_generator_path` to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_generator.load_state_dict(torch.load(save_generator_path))\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init) # Not used\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngAudRzpj0wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = gan.sample_data(1000)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'vanilla_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9uMfdooFxza",
        "colab_type": "text"
      },
      "source": [
        "## DC-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQMxW6V8SUEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAH6qFngioBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGANGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, d):\n",
        "        super(DCGANGenerator, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(z_dim, d, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d, d//2, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d//2)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d//2, d//4, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d//4)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d//4, d//8, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d//8)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d//8, 1, 4, 2, 1)\n",
        "\n",
        "        self.activ = nn.ReLU()\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.z_dim, 1, 1)\n",
        "        x = self.activ(self.deconv1_bn(self.deconv1(x)))\n",
        "        x = self.activ(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = self.activ(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = self.activ(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = torch.tanh(self.deconv5(x)) # Output shape : \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uabmSSpxyTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGANCritic(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super(DCGANCritic, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "        self.activ = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activ(self.conv1(x))\n",
        "        x = self.activ(self.conv2_bn(self.conv2(x)))\n",
        "        x = self.activ(self.conv3_bn(self.conv3(x)))\n",
        "        x = self.activ(self.conv4_bn(self.conv4(x)))\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x.view((-1, 1)) # (batch_size, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fCYdNHN1tck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DC-GAN parameters\n",
        "img_size = 64\n",
        "z_dim = 100\n",
        "G_dim_init = 512 # 1024 or 512\n",
        "C_dim_init = G_dim_init // 8\n",
        "lr = 0.0002\n",
        "n_epochs = 20\n",
        "\n",
        "path_weights_dcgan = 'dc_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjIM2nJ0HCir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size)\n",
        "img_shape = mnist_dataloader.dataset[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZhmMcZKygLT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b04a865a-360b-4d84-b7a8-3f2a0d6a3a7a"
      },
      "source": [
        "TRAIN_MODE = False\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    dcgan_generator = DCGANGenerator(z_dim, G_dim_init)\n",
        "    dcgan_generator.weight_init(mean=0.0, std=0.02)\n",
        "    dcgan_critic = DCGANCritic(C_dim_init)\n",
        "    dcgan_critic.weight_init(mean=0.0, std=0.02)\n",
        "    dcgan = GAN(mnist_dataloader, dcgan_generator, dcgan_critic, lr=lr)\n",
        "    dcgan.train(n_epochs, save_generator_path=path_weights_dcgan,\n",
        "                print_interval=5) # Change `save_generator_path` to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    dcgan_generator = DCGANGenerator(z_dim, G_dim_init)\n",
        "    dcgan_generator.load_state_dict(torch.load(path_weights_dcgan))\n",
        "    dcgan_critic = DCGANCritic(C_dim_init) # Not used\n",
        "    dcgan = GAN(mnist_dataloader, dcgan_generator, dcgan_critic, lr=lr)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gCiB1TMNcHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = dcgan.sample_data(1000)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'dc_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}