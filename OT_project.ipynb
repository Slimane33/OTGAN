{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OT_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIK2SCBi75dB",
        "colab_type": "text"
      },
      "source": [
        "# Optimal Transport Project\n",
        "\n",
        "*Authors : Romain Avouac, Slimane Thabet*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh69TJHokAUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from multiprocessing import cpu_count\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms.functional import to_pil_image, resize, to_tensor\n",
        "from torchvision.transforms.functional import normalize\n",
        "import imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJiJ2yhQRzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU configuration\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScbdHecGSwUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DoubleBatchDataset(data.Dataset):\n",
        "    def __init__(self, dataset1, dataset2):\n",
        "        self.dataset1 = dataset1\n",
        "        self.dataset2 = dataset2\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset1.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.dataset1[index], self.dataset2[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82GY1zvRANnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(batch_size=128, img_size=28, double_batch=False):\n",
        "    \"\"\"Download, preprocess and load MNIST data.\"\"\"\n",
        "    mnist = datasets.MNIST('data', train=True, download=True).data\n",
        "    # Perform transformation directly on raw data rather than in the DataLoader\n",
        "    # => avoids overhead of performing transforms at each batch call \n",
        "    # => much faster epochs.\n",
        "    pics = []\n",
        "    for pic in mnist:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size) # Resize image if needed\n",
        "        pic = to_tensor(pic) # Tensor conversion normalizes in [0,1]\n",
        "        pic = normalize(pic, [0.5], [0.5]) # Normalize values in [-1,1]\n",
        "        pics.append(pic)\n",
        "\n",
        "    mnist = torch.stack(pics)\n",
        "\n",
        "    if double_batch:\n",
        "        mnist = DoubleBatchDataset(mnist, mnist)\n",
        "\n",
        "    return torch.utils.data.DataLoader(mnist, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lpuc57xkX7x",
        "colab_type": "text"
      },
      "source": [
        "## Vanilla GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axC1hgE-kZDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANGenerator(nn.Module):\n",
        "    def __init__(self, input_size, d, output_shape):\n",
        "        super(GANGenerator, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d*2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d*4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, \n",
        "                              output_shape[0] * output_shape[1] * output_shape[2])\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.map1(x))\n",
        "        x = self.act(self.map2(x))\n",
        "        x = self.act(self.map3(x))\n",
        "        x = torch.tanh(self.map4(x))\n",
        "        \n",
        "        return x.view((-1,)+self.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StPNp6QHkcFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANCritic(nn.Module):\n",
        "    def __init__(self, input_size, d):\n",
        "        super(GANCritic, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d//2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d//4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, 1)\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.act(self.map1(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map2(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map3(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = torch.sigmoid(self.map4(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5siAOXTkd8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN():\n",
        "    \n",
        "    def __init__(self, dataloader, generator, critic, lr=0.0001):\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        # default parameters for mnist \n",
        "        self.img_channels = dataloader.dataset[0].shape[0]\n",
        "        self.img_rows = dataloader.dataset[0].shape[1]\n",
        "        self.img_cols = dataloader.dataset[0].shape[2]\n",
        "        self.img_shape = (self.img_channels, self.img_rows, self.img_cols)\n",
        "        self.z_dim = z_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        self.generator = generator.to(device)\n",
        "        self.critic = critic.to(device)\n",
        "\n",
        "        \n",
        "    def sample_data(self, n_sample):\n",
        "        z_random = np.random.randn(n_sample, self.z_dim)\n",
        "        z_random = torch.FloatTensor(z_random).to(device)\n",
        "        samples = self.generator(z_random)\n",
        "        samples = samples.detach().cpu().numpy()\n",
        "        return samples\n",
        "        \n",
        "    def train(self, epochs=100, print_interval=10, save_generator_path=None):\n",
        "        \n",
        "        criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
        "        d_optimizer = optim.Adam(self.critic.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
        "        g_optimizer = optim.Adam(self.generator.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
        "        d_steps = 1\n",
        "        g_steps = 1\n",
        "\n",
        "        t = time()\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            for batch in self.dataloader:\n",
        "                batch = batch.type(torch.FloatTensor).to(device)\n",
        "\n",
        "                for d_index in range(d_steps):\n",
        "                    # 1. Train D on real+fake\n",
        "                    self.critic.zero_grad()\n",
        "\n",
        "                    #  1A: Train D on real\n",
        "                    d_real_data = Variable(batch.to(device))\n",
        "                    d_real_decision = self.critic(d_real_data)\n",
        "                    y_real = Variable(torch.ones(d_real_decision.shape).to(device))\n",
        "                    d_real_error = criterion(d_real_decision, y_real)\n",
        "        \n",
        "                    #  1B: Train D on fake\n",
        "                    d_gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    d_gen_input = Variable(d_gen_input.to(device))\n",
        "                    d_fake_data = self.generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "                    d_fake_decision = self.critic(d_fake_data)\n",
        "                    y_fake = Variable(torch.zeros(d_real_decision.shape).to(device))\n",
        "                    d_fake_error = criterion(d_fake_decision, y_fake) \n",
        "\n",
        "                    # Backward propagation on the sum of the two losses\n",
        "                    d_train_loss = d_real_error + d_fake_error\n",
        "                    d_train_loss.backward()\n",
        "                    d_optimizer.step() # Only optimizes D's parameters\n",
        "        \n",
        "                for g_index in range(g_steps):\n",
        "                    # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "                    self.generator.zero_grad()\n",
        "        \n",
        "                    gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    gen_input = Variable(gen_input.to(device))\n",
        "                    g_fake_data = self.generator(gen_input)\n",
        "                    dg_fake_decision = self.critic(g_fake_data)\n",
        "                    y_ones = Variable(torch.ones(dg_fake_decision.shape).to(device))\n",
        "                    g_error = criterion(dg_fake_decision, y_ones)   # Train G to pretend it's genuine\n",
        "        \n",
        "                    g_error.backward()\n",
        "                    g_optimizer.step()  # Only optimizes G's parameters\n",
        "                    \n",
        "    \n",
        "            if (epoch > 0 and epoch % print_interval == 0) or epoch+1 == epochs:\n",
        "                de = d_train_loss.detach().cpu().numpy()\n",
        "                ge = g_error.detach().cpu().numpy()\n",
        "                print(\"Epoch %s: C_loss =  %s ;  G_loss = %s;  time = %s\" %\n",
        "                      (epoch, de, ge, time()-t))\n",
        "                \n",
        "            # if epoch % 1 == 0:\n",
        "            #     samples = self.sample_data(3)*0.5 + 0.5\n",
        "            #     for img in samples:\n",
        "            #         plt.figure()\n",
        "            #         plt.imshow(img[0,:,:], cmap='gray')\n",
        "            #         plt.show()\n",
        "\n",
        "        if save_generator_path is not None:\n",
        "            torch.save(self.generator.state_dict(), save_generator_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTA9jZhVB6Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vanilla GAN parameters\n",
        "img_size = 28\n",
        "z_dim = 32\n",
        "G_dim_init = 128\n",
        "C_dim_init = 1024\n",
        "\n",
        "lr = 0.0002\n",
        "batch_size = 128\n",
        "n_epochs = 100\n",
        "\n",
        "save_generator_path = 'vanilla_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uivUpAPfBMR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size)\n",
        "img_shape = mnist_dataloader.dataset[0].shape\n",
        "n_pixels = img_shape[0] * img_shape[1] * img_shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-GlOy3aCn9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_MODE = False\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init)\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)\n",
        "    gan.train(n_epochs, save_generator_path=save_generator_path,\n",
        "              print_interval=10) # Change `save_generator_path` to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_generator.load_state_dict(torch.load(save_generator_path))\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init) # Not used\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngAudRzpj0wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = gan.sample_data(500)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'vanilla_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9uMfdooFxza",
        "colab_type": "text"
      },
      "source": [
        "## DC-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQMxW6V8SUEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAH6qFngioBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGANGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, d):\n",
        "        super(DCGANGenerator, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(z_dim, d, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d, d//2, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d//2)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d//2, d//4, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d//4)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d//4, d//8, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d//8)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d//8, 1, 4, 2, 1)\n",
        "\n",
        "        self.activ = nn.ReLU()\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.z_dim, 1, 1)\n",
        "        x = self.activ(self.deconv1_bn(self.deconv1(x)))\n",
        "        x = self.activ(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = self.activ(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = self.activ(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = torch.tanh(self.deconv5(x)) # Output shape : \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uabmSSpxyTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGANCritic(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super(DCGANCritic, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "        self.activ = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activ(self.conv1(x))\n",
        "        x = self.activ(self.conv2_bn(self.conv2(x)))\n",
        "        x = self.activ(self.conv3_bn(self.conv3(x)))\n",
        "        x = self.activ(self.conv4_bn(self.conv4(x)))\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x.view((-1, 1)) # (batch_size, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fCYdNHN1tck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DC-GAN parameters\n",
        "img_size = 64\n",
        "z_dim = 100\n",
        "G_dim_init = 512 # 1024 or 512\n",
        "C_dim_init = G_dim_init // 8\n",
        "\n",
        "lr = 0.0002\n",
        "batch_size = 128\n",
        "n_epochs = 20\n",
        "\n",
        "path_weights_dcgan = 'dc_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjIM2nJ0HCir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size)\n",
        "img_shape = mnist_dataloader.dataset[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZhmMcZKygLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_MODE = False\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    dcgan_generator = DCGANGenerator(z_dim, G_dim_init)\n",
        "    dcgan_generator.weight_init(mean=0.0, std=0.02)\n",
        "    dcgan_critic = DCGANCritic(C_dim_init)\n",
        "    dcgan_critic.weight_init(mean=0.0, std=0.02)\n",
        "    dcgan = GAN(mnist_dataloader, dcgan_generator, dcgan_critic, lr=lr)\n",
        "    dcgan.train(n_epochs, save_generator_path=path_weights_dcgan,\n",
        "                print_interval=5) # Change `save_generator_path` to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    dcgan_generator = DCGANGenerator(z_dim, G_dim_init)\n",
        "    dcgan_generator.load_state_dict(torch.load(path_weights_dcgan))\n",
        "    dcgan_critic = DCGANCritic(C_dim_init) # Not used\n",
        "    dcgan = GAN(mnist_dataloader, dcgan_generator, dcgan_critic, lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gCiB1TMNcHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = dcgan.sample_data(500)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'dc_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JycPG0Nzx0r",
        "colab_type": "text"
      },
      "source": [
        "## OT-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-MMUzS5zy2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OTGANGenerator(nn.Module):\n",
        "    def __init__(self, input_size, init_channels, init_size, kernel_size,\n",
        "                 output_channels):\n",
        "        super(OTGANGenerator, self).__init__()\n",
        "        self.init_channels = init_channels\n",
        "        self.init_size = init_size\n",
        "\n",
        "        self.linear = nn.Linear(input_size, init_channels * init_size * init_size)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        conv_padding_size = (kernel_size - 1) // 2\n",
        "        self.conv1 = nn.Conv2d(init_channels, init_channels // 2, kernel_size, \n",
        "                               padding=conv_padding_size)\n",
        "        self.conv2 = nn.Conv2d(init_channels // 2, init_channels // 4, kernel_size, \n",
        "                               padding=conv_padding_size)\n",
        "        self.conv3 = nn.Conv2d(init_channels // 4, init_channels // 8, kernel_size, \n",
        "                               padding=conv_padding_size)\n",
        "        self.conv4 = nn.Conv2d(init_channels // 8, output_channels, kernel_size,\n",
        "                               padding=conv_padding_size)\n",
        "\n",
        "        self.activ = nn.LeakyReLU(negative_slope=0.2) # TODO : replace it by GLU\n",
        "        self.activ_out = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activ(self.linear(x))\n",
        "        x = x.view((-1, self.init_channels, self.init_size, self.init_size))\n",
        "        x = self.upsample(x)\n",
        "        x = self.activ(self.conv1(x))\n",
        "        x = self.upsample(x)\n",
        "        x = self.activ(self.conv2(x))\n",
        "        x = self.upsample(x)\n",
        "        x = self.activ(self.conv3(x))\n",
        "        x = self.activ_out(self.conv4(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwsj5sRg0Mjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OTGANCritic(nn.Module):\n",
        "    def __init__(self, img_channels, conv1_channels, kernel_size):\n",
        "        super(OTGANCritic, self).__init__()\n",
        "\n",
        "        conv_padding_size = (kernel_size - 1) // 2\n",
        "        self.conv1 = nn.Conv2d(img_channels, conv1_channels, kernel_size,\n",
        "                               padding=conv_padding_size)\n",
        "        self.conv2 = nn.Conv2d(conv1_channels*2, conv1_channels*2, kernel_size, \n",
        "                               stride=2, padding=conv_padding_size)\n",
        "        self.conv3 = nn.Conv2d(conv1_channels*4, conv1_channels*4, kernel_size, \n",
        "                               stride=2, padding=conv_padding_size)\n",
        "        self.conv4 = nn.Conv2d(conv1_channels*8, conv1_channels*8, kernel_size, \n",
        "                               stride=2, padding=conv_padding_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # CReLU : https://github.com/pytorch/pytorch/issues/1327\n",
        "        x = torch.cat((F.relu(x), F.relu(-x)), 1)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.cat((F.relu(x), F.relu(-x)), 1)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.cat((F.relu(x), F.relu(-x)), 1)\n",
        "        x = self.conv4(x)\n",
        "        x = torch.cat((F.relu(x), F.relu(-x)), 1)\n",
        "        x = nn.Flatten()(x)\n",
        "        x = F.normalize(x, dim=1, p=2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVnp5p-H0Wo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OTGAN():\n",
        "    \n",
        "    def __init__(self, dataloader, generator, critic, lr=0.0001):\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        # default parameters for mnist \n",
        "        self.img_channels = dataloader.dataset[0][0].shape[0]\n",
        "        self.img_rows = dataloader.dataset[0][0].shape[1]\n",
        "        self.img_cols = dataloader.dataset[0][0].shape[2]\n",
        "        self.img_shape = (self.img_channels, self.img_rows, self.img_cols)\n",
        "        self.z_dim = z_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        self.generator = generator.to(device)\n",
        "        self.critic = critic.to(device)\n",
        "\n",
        "        \n",
        "    def sample_data(self, n_sample):\n",
        "        z_random = np.random.randn(n_sample, self.z_dim)\n",
        "        z_random = torch.FloatTensor(z_random).to(device)\n",
        "        samples = self.generator(z_random)\n",
        "        samples = samples.detach().cpu().numpy()\n",
        "        return samples\n",
        "\n",
        "\n",
        "    def cost(self, batch_1, batch_2):\n",
        "        norm_1 = torch.norm(batch_1, p=2, dim=1).reshape(-1,1)\n",
        "        norm_2 = torch.norm(batch_2, p=2, dim=1).reshape(-1,1)\n",
        "        cost = 1 - torch.matmul(batch_1, batch_2.transpose(0,1)) / (torch.matmul(norm_1, norm_2.transpose(0,1)))\n",
        "        return cost\n",
        "\n",
        "    def sinkhorn(self, a, b, C, reg=0.002, max_iters=500):\n",
        "    \n",
        "        K = torch.exp(-C/reg)\n",
        "        u = torch.ones_like(a).to(device)\n",
        "        v = torch.ones_like(b).to(device)\n",
        "        for i in range(max_iters):\n",
        "            u = a / torch.matmul(K,v)\n",
        "            v = b / torch.matmul(K.T,u)\n",
        "        return torch.matmul(torch.diag_embed(u), \n",
        "                            torch.matmul(K, torch.diag_embed(v)))\n",
        "\n",
        "        \n",
        "    def train(self, epochs=100, print_interval=10, save_generator_path=None):\n",
        "        \n",
        "        criterion = nn.BCELoss()  # http://pytorch.org/docs/nn.html#bceloss\n",
        "        c_optimizer = optim.Adam(self.critic.parameters(), lr=self.lr, \n",
        "                                 betas=(0.5, 0.999))\n",
        "        g_optimizer = optim.Adam(self.generator.parameters(), lr=self.lr, \n",
        "                                 betas=(0.5, 0.999))\n",
        "        d_steps = 1\n",
        "        g_steps = 1\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            t=time()\n",
        "            loss_to_display = []\n",
        "            \n",
        "            for i, (real_1, real_2) in enumerate(self.dataloader):\n",
        "                \n",
        "                batch_size = real_1.shape[0]\n",
        "\n",
        "                self.critic.zero_grad()\n",
        "                self.generator.zero_grad()\n",
        "    \n",
        "                real_1 = real_1.type(torch.FloatTensor).to(device)\n",
        "                real_2 = real_2.type(torch.FloatTensor).to(device)\n",
        "                \n",
        "                z1 = torch.FloatTensor(np.random.randn(batch_size, \n",
        "                                                       self.z_dim)).to(device)\n",
        "                fake_1 = self.generator(z1)\n",
        "                z2 = torch.FloatTensor(np.random.randn(batch_size, \n",
        "                                                       self.z_dim)).to(device)\n",
        "                fake_2 = self.generator(z2)\n",
        "                \n",
        "                critic_real_1 = self.critic(real_1)\n",
        "                critic_real_2 = self.critic(real_2)\n",
        "                critic_fake_1 = self.critic(fake_1)\n",
        "                critic_fake_2 = self.critic(fake_2)\n",
        "\n",
        "                # Computing all matrices of costs\n",
        "\n",
        "                costs = torch.zeros((4, 4, batch_size, batch_size)).to(device)\n",
        "\n",
        "                costs[0,1] = self.cost(critic_real_1, critic_real_2)\n",
        "                costs[0,2] = self.cost(critic_real_1, critic_fake_1)\n",
        "                costs[0,3] = self.cost(critic_real_1, critic_fake_2)\n",
        "                costs[1,2] = self.cost(critic_real_2, critic_fake_1)\n",
        "                costs[1,3] = self.cost(critic_real_2, critic_fake_2)\n",
        "                costs[2,3] = self.cost(critic_fake_1, critic_fake_2)\n",
        "\n",
        "                # Computing optimal plans for all costs\n",
        "\n",
        "                a = (torch.ones(batch_size) / batch_size).to(device)\n",
        "                b = (torch.ones(batch_size) / batch_size).to(device)\n",
        "                \n",
        "                plans = torch.zeros((4,4, batch_size, batch_size)).to(device)\n",
        "                \n",
        "                plans[0,1] = self.sinkhorn(a, b, costs[0,1], reg=0.01)\n",
        "                plans[0,2] = self.sinkhorn(a, b, costs[0,2], reg=0.01)\n",
        "                plans[0,3] = self.sinkhorn(a, b, costs[0,3], reg=0.01)\n",
        "                plans[1,2] = self.sinkhorn(a, b, costs[1,2], reg=0.01)\n",
        "                plans[1,3] = self.sinkhorn(a, b, costs[1,3], reg=0.01)\n",
        "                plans[2,3] = self.sinkhorn(a, b, costs[2,3], reg=0.01)\n",
        "                \n",
        "\n",
        "                # Computing losses\n",
        "                \n",
        "                losses = torch.zeros((4,4)).to(device)\n",
        "                \n",
        "                losses[0,1] = torch.sum(plans[0,1] * costs[0,1])\n",
        "                losses[0,2] = torch.sum(plans[0,2] * costs[0,2])\n",
        "                losses[0,3] = torch.sum(plans[0,3] * costs[0,3])\n",
        "                losses[1,2] = torch.sum(plans[1,2] * costs[1,2])\n",
        "                losses[1,3] = torch.sum(plans[1,3] * costs[1,3])\n",
        "                losses[2,3] = torch.sum(plans[2,3] * costs[2,3])        \n",
        "                \n",
        "                loss = losses[0,2] + losses[0,3] + losses[1,2] + losses[1,3] - 2 * losses[0,1] - 2 * losses[2,3]\n",
        "\n",
        "                loss.backward()\n",
        "                c_optimizer.step()\n",
        "                g_optimizer.step()\n",
        "             \n",
        "                loss_to_display.append(float(loss.detach().cpu().numpy()))\n",
        "\n",
        "                print(i)\n",
        "                    \n",
        "    \n",
        "            if (epoch > 0 and epoch % print_interval == 0) or epoch+1 == epochs:\n",
        "                train_loss = loss.detach().cpu().numpy()\n",
        "                print(\"Epoch %s: loss = %s;  time = %s\" %\n",
        "                      (epoch, train_loss, time()-t))\n",
        "                \n",
        "            # if epoch % 1 == 0:\n",
        "            #     samples = self.sample_data(3)*0.5 + 0.5\n",
        "            #     for img in samples:\n",
        "            #         plt.figure()\n",
        "            #         plt.imshow(img[0,:,:], cmap='gray')\n",
        "            #         plt.show()\n",
        "\n",
        "        if save_generator_path is not None:\n",
        "            torch.save(self.generator.state_dict(), save_generator_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OvQ1f5EgKLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "img_size = 32\n",
        "n_channels_img = 1\n",
        "batch_size = 512\n",
        "\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size, \n",
        "                              double_batch=True)\n",
        "img_shape = mnist_dataloader.dataset[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCYPdlWa1LHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OT-GAN parameters\n",
        "z_dim = 100\n",
        "lr = 0.0003\n",
        "n_epochs = 20\n",
        "\n",
        "gen_params = (\n",
        "    z_dim,\n",
        "    1024, # Number of output channels of the generator's first conv layer\n",
        "    4, # Output size of the generator's first conv layer\n",
        "    5, # Kernel size for all the generator's conv layers\n",
        "    n_channels_img # Number of output channels (here 1 because B&W pictures)\n",
        "    )\n",
        "\n",
        "critic_params = (\n",
        "    n_channels_img, # Number of input channels (here 1 because B&W pictures)\n",
        "    128, # Number of output channels of the critic's first conv layer\n",
        "    5 # Kernel size for all the critic's conv layers\n",
        "    )\n",
        "\n",
        "path_weights_otgan = 'ot_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxKfKV8oTsxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_MODE = True\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    otgan_generator = OTGANGenerator(*gen_params)\n",
        "    otgan_critic = OTGANCritic(*critic_params)\n",
        "    otgan = OTGAN(mnist_dataloader, otgan_generator, otgan_critic, lr=lr)\n",
        "    otgan.train(n_epochs, save_generator_path=path_weights_otgan,\n",
        "                print_interval=1) # Change `save_generator_path` to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    otgan_generator = OTGANGenerator(z_dim, G_dim_init)\n",
        "    otgan_generator.load_state_dict(torch.load(path_weights_otgan))\n",
        "    otgan_critic = OTGANCritic(C_dim_init) # Not used\n",
        "    otgan = OTGAN(mnist_dataloader, otgan_generator, otgan_critic, lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiTcFbIqWWO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = otgan.sample_data(500)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'ot_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpNQnBFAVYFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}