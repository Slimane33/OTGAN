{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OT_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIK2SCBi75dB",
        "colab_type": "text"
      },
      "source": [
        "# Optimal Transport Project\n",
        "\n",
        "*Authors : Romain Avouac, Slimane Thabet*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh69TJHokAUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from multiprocessing import cpu_count\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms.functional import to_pil_image, resize, to_tensor\n",
        "from torchvision.transforms.functional import normalize\n",
        "import imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJiJ2yhQRzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU configuration\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt9mVG5lIP6g",
        "colab_type": "text"
      },
      "source": [
        "## Load and preprocess MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82GY1zvRANnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(batch_size=128, img_size=28):\n",
        "    \"\"\"Download, preprocess and load MNIST data.\"\"\"\n",
        "    mnist = datasets.MNIST('data', train=True, download=True).data\n",
        "    # Perform transformation directly on raw data rather than in the DataLoader\n",
        "    # => avoids overhead of transforming at each batch call => much faster epochs.\n",
        "    pics = []\n",
        "    for pic in mnist:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size) # Resize image if needed\n",
        "        pic = to_tensor(pic)\n",
        "        pic = normalize(pic, 0.5, 0.5) # Normalize in [-1,1]\n",
        "        pics.append(pic)\n",
        "\n",
        "    mnist = torch.stack(pics)\n",
        "\n",
        "    return torch.utils.data.DataLoader(mnist, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lpuc57xkX7x",
        "colab_type": "text"
      },
      "source": [
        "## Vanilla GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axC1hgE-kZDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANGenerator(nn.Module):\n",
        "    def __init__(self, input_size, d, output_shape):\n",
        "        super(GANGenerator, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d*2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d*4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, \n",
        "                              output_shape[0] * output_shape[1] * output_shape[2])\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.map1(x))\n",
        "        x = self.act(self.map2(x))\n",
        "        x = self.act(self.map3(x))\n",
        "        x = torch.tanh(self.map4(x))\n",
        "        \n",
        "        return x.view((-1,)+self.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StPNp6QHkcFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANCritic(nn.Module):\n",
        "    def __init__(self, input_size, d):\n",
        "        super(GANCritic, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d//2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d//4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, 1)\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.act(self.map1(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map2(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map3(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = torch.sigmoid(self.map4(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5siAOXTkd8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN():\n",
        "    \n",
        "    def __init__(self, dataloader, generator, critic, lr=0.0001):\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        # default parameters for mnist \n",
        "        self.img_channels = dataloader.dataset[0].shape[0]\n",
        "        self.img_rows = dataloader.dataset[0].shape[1]\n",
        "        self.img_cols = dataloader.dataset[0].shape[2]\n",
        "        self.img_shape = (self.img_channels, self.img_rows, self.img_cols)\n",
        "        self.z_dim = z_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        self.generator = generator.to(device)\n",
        "        self.critic = critic.to(device)\n",
        "\n",
        "        \n",
        "    def sample_data(self, n_sample):\n",
        "        z_random = np.random.randn(n_sample, self.z_dim)\n",
        "        z_random = torch.FloatTensor(z_random).to(device)\n",
        "        samples = self.generator(z_random)\n",
        "        samples = samples.detach().cpu().numpy()\n",
        "        return samples\n",
        "        \n",
        "    def train(self, epochs=100, print_interval=10, save_generator_path=None):\n",
        "        \n",
        "        criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
        "        d_optimizer = optim.Adam(self.critic.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
        "        g_optimizer = optim.Adam(self.generator.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
        "        d_steps = 1\n",
        "        g_steps = 1\n",
        "\n",
        "        t = time()\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            for batch in self.dataloader:\n",
        "                batch = batch.type(torch.FloatTensor).to(device)\n",
        "\n",
        "                for d_index in range(d_steps):\n",
        "                    # 1. Train D on real+fake\n",
        "                    self.critic.zero_grad()\n",
        "\n",
        "                    #  1A: Train D on real\n",
        "                    d_real_data = Variable(batch.to(device))\n",
        "                    d_real_decision = self.critic(d_real_data)\n",
        "                    y_real = Variable(torch.ones(d_real_decision.shape).to(device))\n",
        "                    d_real_error = criterion(d_real_decision, y_real)\n",
        "        \n",
        "                    #  1B: Train D on fake\n",
        "                    d_gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    d_gen_input = Variable(d_gen_input.to(device))\n",
        "                    d_fake_data = self.generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "                    d_fake_decision = self.critic(d_fake_data)\n",
        "                    y_fake = Variable(torch.zeros(d_real_decision.shape).to(device))\n",
        "                    d_fake_error = criterion(d_fake_decision, y_fake) \n",
        "\n",
        "                    # Backward propagation on the sum of the two losses\n",
        "                    d_train_loss = d_real_error + d_fake_error\n",
        "                    d_train_loss.backward()\n",
        "                    d_optimizer.step() # Only optimizes D's parameters\n",
        "        \n",
        "                for g_index in range(g_steps):\n",
        "                    # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "                    self.generator.zero_grad()\n",
        "        \n",
        "                    gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    gen_input = Variable(gen_input.to(device))\n",
        "                    g_fake_data = self.generator(gen_input)\n",
        "                    dg_fake_decision = self.critic(g_fake_data)\n",
        "                    y_ones = Variable(torch.ones(dg_fake_decision.shape).to(device))\n",
        "                    g_error = criterion(dg_fake_decision, y_ones)   # Train G to pretend it's genuine\n",
        "        \n",
        "                    g_error.backward()\n",
        "                    g_optimizer.step()  # Only optimizes G's parameters\n",
        "                    \n",
        "    \n",
        "            if (epoch > 0 and epoch % print_interval == 0) or epoch+1 == epochs:\n",
        "                de = d_train_loss.detach().cpu().numpy()\n",
        "                ge = g_error.detach().cpu().numpy()\n",
        "                print(\"Epoch %s: C_loss =  %s ;  G_loss = %s;  time = %s\" %\n",
        "                      (epoch, de, ge, time()-t))\n",
        "                \n",
        "            # if epoch % 1 == 0:\n",
        "            #     samples = self.sample_data(3)*0.5 + 0.5\n",
        "            #     for img in samples:\n",
        "            #         plt.figure()\n",
        "            #         plt.imshow(img[0,:,:], cmap='gray')\n",
        "            #         plt.show()\n",
        "\n",
        "        if save_generator_path is not None:\n",
        "            torch.save(self.generator.state_dict(), save_generator_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTA9jZhVB6Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vanilla GAN parameters\n",
        "img_size = 28 # Keep initial MNIST size\n",
        "z_dim = 100\n",
        "G_dim_init = 128\n",
        "C_dim_init = 1024\n",
        "\n",
        "lr = 0.0002\n",
        "batch_size = 128\n",
        "n_epochs = 100\n",
        "\n",
        "save_generator_path = 'vanilla_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uivUpAPfBMR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size)\n",
        "img_shape = mnist_dataloader.dataset[0].shape\n",
        "n_pixels = img_shape[0] * img_shape[1] * img_shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-GlOy3aCn9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "6354d871-ca4e-4b94-e100-f0b395b2f754"
      },
      "source": [
        "TRAIN_MODE = True\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init)\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)\n",
        "    gan.train(n_epochs, save_generator_path=save_generator_path) # Change path to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_generator.load_state_dict(torch.load(save_generator_path))\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init) # Not used\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10: C_loss =  0.4421556 ;  G_loss = 2.6215782;  time = 34.57757544517517\n",
            "Epoch 20: C_loss =  0.6888797 ;  G_loss = 1.6280651;  time = 66.4431402683258\n",
            "Epoch 30: C_loss =  0.9987544 ;  G_loss = 1.8691449;  time = 97.94661331176758\n",
            "Epoch 40: C_loss =  0.8366662 ;  G_loss = 1.7507833;  time = 129.45234441757202\n",
            "Epoch 50: C_loss =  0.826293 ;  G_loss = 1.4914486;  time = 160.96948385238647\n",
            "Epoch 60: C_loss =  0.844104 ;  G_loss = 1.2613406;  time = 192.32516193389893\n",
            "Epoch 70: C_loss =  0.98980445 ;  G_loss = 1.2515063;  time = 223.7138316631317\n",
            "Epoch 80: C_loss =  1.1156857 ;  G_loss = 1.732059;  time = 255.320326089859\n",
            "Epoch 90: C_loss =  1.0733883 ;  G_loss = 1.140757;  time = 286.79772424697876\n",
            "Epoch 99: C_loss =  1.0112252 ;  G_loss = 1.2990302;  time = 315.51535511016846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngAudRzpj0wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = gan.sample_data(1000)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'vanilla_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9uMfdooFxza",
        "colab_type": "text"
      },
      "source": [
        "## DC-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQMxW6V8SUEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAH6qFngioBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGANGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, d):\n",
        "        super(DCGANGenerator, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(z_dim, d, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d, d//2, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d//2)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d//2, d//4, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d//4)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d//4, d//8, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d//8)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d//8, 1, 4, 2, 1)\n",
        "\n",
        "        self.activ = nn.ReLU()\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.z_dim, 1, 1)\n",
        "        x = self.activ(self.deconv1_bn(self.deconv1(x)))\n",
        "        x = self.activ(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = self.activ(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = self.activ(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = torch.tanh(self.deconv5(x)) # Output shape : \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uabmSSpxyTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGANCritic(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super(DCGANCritic, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "        self.activ = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activ(self.conv1(x))\n",
        "        x = self.activ(self.conv2_bn(self.conv2(x)))\n",
        "        x = self.activ(self.conv3_bn(self.conv3(x)))\n",
        "        x = self.activ(self.conv4_bn(self.conv4(x)))\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x.view((-1, 1)) # (batch_size, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fCYdNHN1tck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DC-GAN parameters\n",
        "img_size = 64\n",
        "z_dim = 100\n",
        "G_dim_init = 512 # 1024 or 512\n",
        "C_dim_init = G_dim_init // 8\n",
        "lr = 0.0002\n",
        "n_epochs = 20\n",
        "\n",
        "path_weights_dcgan = 'dc_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjIM2nJ0HCir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size)\n",
        "img_shape = mnist_dataloader.dataset[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZhmMcZKygLT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "3296be19-ce54-4a38-c2c4-a25ffeac154c"
      },
      "source": [
        "TRAIN_MODE = True\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    dcgan_generator = DCGANGenerator(z_dim, G_dim_init)\n",
        "    dcgan_generator.weight_init(mean=0.0, std=0.02)\n",
        "    dcgan_critic = DCGANCritic(C_dim_init)\n",
        "    dcgan_critic.weight_init(mean=0.0, std=0.02)\n",
        "    dcgan = GAN(mnist_dataloader, dcgan_generator, dcgan_critic, lr=lr)\n",
        "    dcgan.train(n_epochs, save_generator_path=path_weights_dcgan,\n",
        "                print_interval=1) # Change path to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    dcgan_generator = DCGANGenerator(z_dim, G_dim_init)\n",
        "    gan_generator.load_state_dict(torch.load(path_weights_dcgan))\n",
        "    dcgan_critic = DCGANCritic(C_dim_init) # Not used\n",
        "    dcgan = GAN(mnist_dataloader, dcgan_generator, dcgan_critic, lr=lr)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: C_loss =  0.48784274 ;  G_loss = 2.0608;  time = 93.96772336959839\n",
            "Epoch 2: C_loss =  0.2936925 ;  G_loss = 4.147394;  time = 140.93153953552246\n",
            "Epoch 3: C_loss =  0.19924375 ;  G_loss = 2.7586212;  time = 187.89247012138367\n",
            "Epoch 4: C_loss =  0.22999239 ;  G_loss = 3.4658613;  time = 234.85290145874023\n",
            "Epoch 5: C_loss =  0.11085105 ;  G_loss = 5.0173283;  time = 281.80547976493835\n",
            "Epoch 6: C_loss =  0.25720948 ;  G_loss = 4.0861044;  time = 328.77236771583557\n",
            "Epoch 7: C_loss =  0.15680411 ;  G_loss = 4.3106117;  time = 375.74854826927185\n",
            "Epoch 8: C_loss =  0.5543426 ;  G_loss = 2.4007347;  time = 422.71264481544495\n",
            "Epoch 9: C_loss =  0.07505908 ;  G_loss = 4.055755;  time = 469.6685416698456\n",
            "Epoch 10: C_loss =  0.6098065 ;  G_loss = 2.4486609;  time = 516.6242158412933\n",
            "Epoch 11: C_loss =  0.37127236 ;  G_loss = 3.9166965;  time = 563.5892198085785\n",
            "Epoch 12: C_loss =  0.050106414 ;  G_loss = 3.867641;  time = 610.55885887146\n",
            "Epoch 13: C_loss =  0.40300643 ;  G_loss = 4.5084662;  time = 657.5340914726257\n",
            "Epoch 14: C_loss =  0.051679105 ;  G_loss = 4.840312;  time = 704.4748315811157\n",
            "Epoch 15: C_loss =  0.06110603 ;  G_loss = 4.1252446;  time = 751.4265038967133\n",
            "Epoch 16: C_loss =  0.32671624 ;  G_loss = 2.6450272;  time = 798.3788220882416\n",
            "Epoch 17: C_loss =  0.82576984 ;  G_loss = 2.515314;  time = 845.3259465694427\n",
            "Epoch 18: C_loss =  0.39742643 ;  G_loss = 3.7014759;  time = 892.2777001857758\n",
            "Epoch 19: C_loss =  0.018265154 ;  G_loss = 4.623991;  time = 939.2183260917664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gCiB1TMNcHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = dcgan.sample_data(1000)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'dc_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}