{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OT_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIK2SCBi75dB",
        "colab_type": "text"
      },
      "source": [
        "# Optimal Transport Project\n",
        "\n",
        "*Authors : Romain Avouac, Slimane Thabet*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh69TJHokAUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from multiprocessing import cpu_count\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "import imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJiJ2yhQRzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU configuration\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt9mVG5lIP6g",
        "colab_type": "text"
      },
      "source": [
        "## Load an preprocess MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyGWBJ5r5Tgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST pictures as Torch dataloader\n",
        "batch_size = 128\n",
        "\n",
        "mnist = datasets.MNIST('data', train=True, download=True).data.float() / 256\n",
        "# Perform transformation directly on raw data rather than in the DataLoader\n",
        "# => avoids overhead of transforming at each batch call => much faster epochs.\n",
        "mnist = transforms.Normalize((0.5,), (0.5,))(mnist) # Normalize in [-1,1]\n",
        "mnist = mnist.unsqueeze(-1) # Add channel dimension\n",
        "mnist_dataloader = torch.utils.data.DataLoader(mnist, batch_size=batch_size, \n",
        "                                               shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ix20IWh8REZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = mnist_dataloader.dataset[0].shape\n",
        "n_pixels = img_shape[0] * img_shape[1] * img_shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lpuc57xkX7x",
        "colab_type": "text"
      },
      "source": [
        "## Vanilla GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axC1hgE-kZDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANGenerator(nn.Module):\n",
        "    def __init__(self, input_size, d1, output_shape):\n",
        "        super(GANGenerator, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d1)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d1*2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d1*4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, \n",
        "                              output_shape[0] * output_shape[1] * output_shape[2])\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.act_out = nn.Tanh()\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.map1(x))\n",
        "        x = self.act(self.map2(x))\n",
        "        x = self.act(self.map3(x))\n",
        "        x = self.act_out(self.map4(x))\n",
        "        \n",
        "        return torch.reshape(x, (-1,)+self.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StPNp6QHkcFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANCritic(nn.Module):\n",
        "    def __init__(self, input_size, d1):\n",
        "        super(GANCritic, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d1)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d1//2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d1//4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, 1)\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.act(self.map1(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map2(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map3(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = torch.sigmoid(self.map4(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5siAOXTkd8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN():\n",
        "    \n",
        "    def __init__(self, dataloader, generator, critic, lr=0.0001):\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        # default parameters for mnist \n",
        "        self.img_rows = dataloader.dataset[0].shape[0]\n",
        "        self.img_cols = dataloader.dataset[0].shape[1]\n",
        "        self.img_channels = dataloader.dataset[0].shape[2]\n",
        "        self.img_shape = (self.img_channels, self.img_rows, self.img_cols)\n",
        "        self.z_dim = z_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        self.generator = generator.to(device)\n",
        "        self.critic = critic.to(device)\n",
        "\n",
        "        \n",
        "    def sample_data(self, n_sample):\n",
        "        z_random = np.random.randn(n_sample, self.z_dim)\n",
        "        z_random = torch.FloatTensor(z_random).to(device)\n",
        "        samples = self.generator(z_random)\n",
        "        samples = samples.detach().cpu().numpy()\n",
        "        return samples\n",
        "        \n",
        "    def train(self, epochs=100, print_interval=10, save_generator_path=None):\n",
        "        \n",
        "        criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
        "        d_optimizer = optim.Adam(self.critic.parameters(), lr=self.lr)\n",
        "        g_optimizer = optim.Adam(self.generator.parameters(), lr=self.lr)\n",
        "        d_steps = 1\n",
        "        g_steps = 1\n",
        "\n",
        "        t = time()\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            for batch in self.dataloader:\n",
        "                batch = batch.type(torch.FloatTensor).to(device)\n",
        "\n",
        "                for d_index in range(d_steps):\n",
        "                    # 1. Train D on real+fake\n",
        "                    self.critic.zero_grad()\n",
        "\n",
        "                    #  1A: Train D on real\n",
        "                    d_real_data = Variable(batch.to(device))\n",
        "                    d_real_decision = self.critic(d_real_data)\n",
        "                    y_real = Variable(torch.ones(d_real_decision.shape).to(device))\n",
        "                    d_real_error = criterion(d_real_decision, y_real)\n",
        "        \n",
        "                    #  1B: Train D on fake\n",
        "                    d_gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    d_gen_input = Variable(d_gen_input.to(device))\n",
        "                    d_fake_data = self.generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "                    d_fake_decision = self.critic(d_fake_data)\n",
        "                    y_fake = Variable(torch.zeros(d_real_decision.shape).to(device))\n",
        "                    d_fake_error = criterion(d_fake_decision, y_fake) \n",
        "\n",
        "                    # Backward propagation on the sum of the two losses\n",
        "                    d_train_loss = d_real_error + d_fake_error\n",
        "                    d_train_loss.backward()\n",
        "                    d_optimizer.step() # Only optimizes D's parameters\n",
        "        \n",
        "                for g_index in range(g_steps):\n",
        "                    # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "                    self.generator.zero_grad()\n",
        "        \n",
        "                    gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    gen_input = Variable(gen_input.to(device))\n",
        "                    g_fake_data = self.generator(gen_input)\n",
        "                    dg_fake_decision = self.critic(g_fake_data)\n",
        "                    y_ones = Variable(torch.ones(dg_fake_decision.shape).to(device))\n",
        "                    g_error = criterion(dg_fake_decision, y_ones)   # Train G to pretend it's genuine\n",
        "        \n",
        "                    g_error.backward()\n",
        "                    g_optimizer.step()  # Only optimizes G's parameters\n",
        "                    \n",
        "    \n",
        "            if epoch > 0 and epoch % print_interval == 0:\n",
        "                de = d_train_loss.detach().cpu().numpy()\n",
        "                ge = g_error.detach().cpu().numpy()\n",
        "                print(\"Epoch %s: C_loss =  %s ;  G_loss = %s;  time = %s\" %\n",
        "                      (epoch, de, ge, time()-t))\n",
        "                \n",
        "            # if epoch % (print_interval*5) == 0:\n",
        "            #     samples = self.sample_data(3)*0.5 + 0.5\n",
        "            #     for img in samples:\n",
        "            #         plt.figure()\n",
        "            #         plt.imshow(img[0,:,:], cmap='gray')\n",
        "            #         plt.show()\n",
        "\n",
        "        if save_generator_path is not None:\n",
        "            torch.save(self.generator.state_dict(), save_generator_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTA9jZhVB6Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vanilla GAN parameters\n",
        "z_dim = 32\n",
        "G_dim_init = 128\n",
        "C_dim_init = 1024\n",
        "lr = 0.0002\n",
        "n_epochs = 150\n",
        "\n",
        "save_generator_path = f'vanilla_gan_gen_{n_epochs}_epochs.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-GlOy3aCn9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "81113ad2-b744-4ad4-c72f-198d7d476f39"
      },
      "source": [
        "TRAIN_MODE = True\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init)\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)\n",
        "    gan.train(n_epochs, save_generator_path=save_generator_path) # Change path to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_generator.load_state_dict(torch.load(save_generator_path))\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init) # Not used\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10: C_loss =  0.30912006 ;  G_loss = 2.8868084;  time = 34.08194589614868\n",
            "Epoch 20: C_loss =  0.47326016 ;  G_loss = 2.9026325;  time = 65.56107878684998\n",
            "Epoch 30: C_loss =  0.6197822 ;  G_loss = 2.2964196;  time = 96.43275094032288\n",
            "Epoch 40: C_loss =  1.0139887 ;  G_loss = 1.4544802;  time = 127.59009408950806\n",
            "Epoch 50: C_loss =  0.86324716 ;  G_loss = 1.7470224;  time = 159.03242945671082\n",
            "Epoch 60: C_loss =  1.1276977 ;  G_loss = 1.1454122;  time = 190.4057993888855\n",
            "Epoch 70: C_loss =  0.96821135 ;  G_loss = 1.3937525;  time = 221.68380689620972\n",
            "Epoch 80: C_loss =  1.1212473 ;  G_loss = 1.1865845;  time = 253.12764072418213\n",
            "Epoch 90: C_loss =  1.1003426 ;  G_loss = 1.0400988;  time = 284.3145122528076\n",
            "Epoch 100: C_loss =  1.0390577 ;  G_loss = 1.0540663;  time = 316.03295254707336\n",
            "Epoch 110: C_loss =  1.1998593 ;  G_loss = 1.0106716;  time = 347.29128646850586\n",
            "Epoch 120: C_loss =  1.0770011 ;  G_loss = 1.1528316;  time = 378.84757900238037\n",
            "Epoch 130: C_loss =  1.3117784 ;  G_loss = 0.93336123;  time = 410.05022859573364\n",
            "Epoch 140: C_loss =  1.194684 ;  G_loss = 1.0407562;  time = 441.3500576019287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngAudRzpj0wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = (gan.sample_data(200)*0.5 + 0.5) * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, -1)\n",
        "\n",
        "gif_path = 'test.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9uMfdooFxza",
        "colab_type": "text"
      },
      "source": [
        "## DC-GAN"
      ]
    }
  ]
}