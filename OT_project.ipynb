{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OT_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIK2SCBi75dB",
        "colab_type": "text"
      },
      "source": [
        "# Optimal Transport Project\n",
        "\n",
        "*Authors : Romain Avouac, Slimane Thabet*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh69TJHokAUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from multiprocessing import cpu_count\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms.functional import to_pil_image, resize, to_tensor\n",
        "from torchvision.transforms.functional import normalize\n",
        "import imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJiJ2yhQRzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU configuration\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScbdHecGSwUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DoubleBatchDataset(data.Dataset):\n",
        "    def __init__(self, dataset1, dataset2):\n",
        "        self.dataset1 = dataset1\n",
        "        self.dataset2 = dataset2\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset1.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.dataset1[index], self.dataset2[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82GY1zvRANnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(batch_size=128, img_size=28, double_batch=False):\n",
        "    \"\"\"Download, preprocess and load MNIST data.\"\"\"\n",
        "    mnist = datasets.MNIST('data', train=True, download=True).data\n",
        "    # Perform transformation directly on raw data rather than in the DataLoader\n",
        "    # => avoids overhead of performing transforms at each batch call \n",
        "    # => much faster epochs.\n",
        "    pics = []\n",
        "    for pic in mnist:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size) # Resize image if needed\n",
        "        pic = to_tensor(pic) # Tensor conversion normalizes in [0,1]\n",
        "        pic = normalize(pic, [0.5], [0.5]) # Normalize values in [-1,1]\n",
        "        pics.append(pic)\n",
        "\n",
        "    mnist = torch.stack(pics)\n",
        "\n",
        "    if double_batch:\n",
        "        mnist = DoubleBatchDataset(mnist, mnist)\n",
        "\n",
        "    return torch.utils.data.DataLoader(mnist, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lpuc57xkX7x",
        "colab_type": "text"
      },
      "source": [
        "## Vanilla GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axC1hgE-kZDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANGenerator(nn.Module):\n",
        "    def __init__(self, input_size, d, output_shape):\n",
        "        super(GANGenerator, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d*2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d*4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, \n",
        "                              output_shape[0] * output_shape[1] * output_shape[2])\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.map1(x))\n",
        "        x = self.act(self.map2(x))\n",
        "        x = self.act(self.map3(x))\n",
        "        x = torch.tanh(self.map4(x))\n",
        "        \n",
        "        return x.view((-1,)+self.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StPNp6QHkcFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANCritic(nn.Module):\n",
        "    def __init__(self, input_size, d):\n",
        "        super(GANCritic, self).__init__()\n",
        "\n",
        "        self.map1 = nn.Linear(input_size, d)\n",
        "        self.map2 = nn.Linear(self.map1.out_features, d//2)\n",
        "        self.map3 = nn.Linear(self.map2.out_features, d//4)\n",
        "        self.map4 = nn.Linear(self.map3.out_features, 1)\n",
        "\n",
        "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.act(self.map1(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map2(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.map3(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = torch.sigmoid(self.map4(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5siAOXTkd8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN():\n",
        "    \n",
        "    def __init__(self, dataloader, generator, critic, lr=0.0001):\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        # default parameters for mnist \n",
        "        self.img_channels = dataloader.dataset[0].shape[0]\n",
        "        self.img_rows = dataloader.dataset[0].shape[1]\n",
        "        self.img_cols = dataloader.dataset[0].shape[2]\n",
        "        self.img_shape = (self.img_channels, self.img_rows, self.img_cols)\n",
        "        self.z_dim = z_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        self.generator = generator.to(device)\n",
        "        self.critic = critic.to(device)\n",
        "\n",
        "        \n",
        "    def sample_data(self, n_sample):\n",
        "        z_random = np.random.randn(n_sample, self.z_dim)\n",
        "        z_random = torch.FloatTensor(z_random).to(device)\n",
        "        samples = self.generator(z_random)\n",
        "        samples = samples.detach().cpu().numpy()\n",
        "        return samples\n",
        "        \n",
        "    def train(self, epochs=100, print_interval=10, save_generator_path=None):\n",
        "        \n",
        "        criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
        "        d_optimizer = optim.Adam(self.critic.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
        "        g_optimizer = optim.Adam(self.generator.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
        "        d_steps = 1\n",
        "        g_steps = 1\n",
        "\n",
        "        t = time()\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            for batch in self.dataloader:\n",
        "                batch = batch.type(torch.FloatTensor).to(device)\n",
        "\n",
        "                for d_index in range(d_steps):\n",
        "                    # 1. Train D on real+fake\n",
        "                    self.critic.zero_grad()\n",
        "\n",
        "                    #  1A: Train D on real\n",
        "                    d_real_data = Variable(batch.to(device))\n",
        "                    d_real_decision = self.critic(d_real_data)\n",
        "                    y_real = Variable(torch.ones(d_real_decision.shape).to(device))\n",
        "                    d_real_error = criterion(d_real_decision, y_real)\n",
        "        \n",
        "                    #  1B: Train D on fake\n",
        "                    d_gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    d_gen_input = Variable(d_gen_input.to(device))\n",
        "                    d_fake_data = self.generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "                    d_fake_decision = self.critic(d_fake_data)\n",
        "                    y_fake = Variable(torch.zeros(d_real_decision.shape).to(device))\n",
        "                    d_fake_error = criterion(d_fake_decision, y_fake) \n",
        "\n",
        "                    # Backward propagation on the sum of the two losses\n",
        "                    d_train_loss = d_real_error + d_fake_error\n",
        "                    d_train_loss.backward()\n",
        "                    d_optimizer.step() # Only optimizes D's parameters\n",
        "        \n",
        "                for g_index in range(g_steps):\n",
        "                    # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "                    self.generator.zero_grad()\n",
        "        \n",
        "                    gen_input = torch.randn((batch.shape[0], self.z_dim))\n",
        "                    gen_input = Variable(gen_input.to(device))\n",
        "                    g_fake_data = self.generator(gen_input)\n",
        "                    dg_fake_decision = self.critic(g_fake_data)\n",
        "                    y_ones = Variable(torch.ones(dg_fake_decision.shape).to(device))\n",
        "                    g_error = criterion(dg_fake_decision, y_ones)   # Train G to pretend it's genuine\n",
        "        \n",
        "                    g_error.backward()\n",
        "                    g_optimizer.step()  # Only optimizes G's parameters\n",
        "                    \n",
        "    \n",
        "            if (epoch > 0 and epoch % print_interval == 0) or epoch+1 == epochs:\n",
        "                de = d_train_loss.detach().cpu().numpy()\n",
        "                ge = g_error.detach().cpu().numpy()\n",
        "                print(\"Epoch %s: C_loss =  %s ;  G_loss = %s;  time = %s\" %\n",
        "                      (epoch, de, ge, time()-t))\n",
        "                \n",
        "            # if epoch % 1 == 0:\n",
        "            #     samples = self.sample_data(3)*0.5 + 0.5\n",
        "            #     for img in samples:\n",
        "            #         plt.figure()\n",
        "            #         plt.imshow(img[0,:,:], cmap='gray')\n",
        "            #         plt.show()\n",
        "\n",
        "        if save_generator_path is not None:\n",
        "            torch.save(self.generator.state_dict(), save_generator_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTA9jZhVB6Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vanilla GAN parameters\n",
        "img_size = 28\n",
        "z_dim = 100\n",
        "G_dim_init = 128\n",
        "C_dim_init = 1024\n",
        "\n",
        "lr = 0.0002\n",
        "batch_size = 128\n",
        "n_epochs = 100\n",
        "\n",
        "save_generator_path = 'vanilla_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uivUpAPfBMR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size)\n",
        "img_shape = mnist_dataloader.dataset[0].shape\n",
        "n_pixels = img_shape[0] * img_shape[1] * img_shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-GlOy3aCn9v",
        "colab_type": "code",
        "outputId": "94097e52-3962-4199-bd8d-178157ff9faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "TRAIN_MODE = False\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init)\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)\n",
        "    gan.train(n_epochs, save_generator_path=save_generator_path,\n",
        "              print_interval=10) # Change `save_generator_path` to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    gan_generator = GANGenerator(z_dim, G_dim_init, img_shape)\n",
        "    gan_generator.load_state_dict(torch.load(save_generator_path))\n",
        "    gan_critic = GANCritic(n_pixels, C_dim_init) # Not used\n",
        "    gan = GAN(mnist_dataloader, gan_generator, gan_critic, lr=lr)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f798dd8b8c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Load previously trained generator weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgan_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGANGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_dim_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mgan_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_generator_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgan_critic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGANCritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_dim_init\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Not used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GANGenerator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngAudRzpj0wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = gan.sample_data(500)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'vanilla_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9uMfdooFxza",
        "colab_type": "text"
      },
      "source": [
        "## DC-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQMxW6V8SUEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAH6qFngioBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGANGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, d):\n",
        "        super(DCGANGenerator, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(z_dim, d, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d, d//2, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d//2)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d//2, d//4, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d//4)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d//4, d//8, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d//8)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d//8, 1, 4, 2, 1)\n",
        "\n",
        "        self.activ = nn.ReLU()\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.z_dim, 1, 1)\n",
        "        x = self.activ(self.deconv1_bn(self.deconv1(x)))\n",
        "        x = self.activ(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = self.activ(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = self.activ(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = torch.tanh(self.deconv5(x)) # Output shape : \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uabmSSpxyTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGANCritic(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super(DCGANCritic, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "        self.activ = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activ(self.conv1(x))\n",
        "        x = self.activ(self.conv2_bn(self.conv2(x)))\n",
        "        x = self.activ(self.conv3_bn(self.conv3(x)))\n",
        "        x = self.activ(self.conv4_bn(self.conv4(x)))\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x.view((-1, 1)) # (batch_size, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fCYdNHN1tck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DC-GAN parameters\n",
        "img_size = 64\n",
        "z_dim = 100\n",
        "G_dim_init = 512 # 1024 or 512\n",
        "C_dim_init = G_dim_init // 8\n",
        "\n",
        "lr = 0.0002\n",
        "batch_size = 128\n",
        "n_epochs = 20\n",
        "\n",
        "path_weights_dcgan = 'dc_gan_gen.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjIM2nJ0HCir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size)\n",
        "img_shape = mnist_dataloader.dataset[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZhmMcZKygLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_MODE = True\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    dcgan_generator = DCGANGenerator(z_dim, G_dim_init)\n",
        "    dcgan_generator.weight_init(mean=0.0, std=0.02)\n",
        "    dcgan_critic = DCGANCritic(C_dim_init)\n",
        "    dcgan_critic.weight_init(mean=0.0, std=0.02)\n",
        "    dcgan = GAN(mnist_dataloader, dcgan_generator, dcgan_critic, lr=lr)\n",
        "    dcgan.train(n_epochs, save_generator_path=path_weights_dcgan,\n",
        "                print_interval=5) # Change `save_generator_path` to None to prevent saving weights\n",
        "else:\n",
        "    # Load previously trained generator weights\n",
        "    dcgan_generator = DCGANGenerator(z_dim, G_dim_init)\n",
        "    dcgan_generator.load_state_dict(torch.load(path_weights_dcgan))\n",
        "    dcgan_critic = DCGANCritic(C_dim_init) # Not used\n",
        "    dcgan = GAN(mnist_dataloader, dcgan_generator, dcgan_critic, lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gCiB1TMNcHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = dcgan.sample_data(500)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'dc_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JycPG0Nzx0r",
        "colab_type": "text"
      },
      "source": [
        "## OT-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-MMUzS5zy2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OTGANGenerator(nn.Module):\n",
        "    def __init__(self, input_size, kernel_size=5):\n",
        "        super(OTGANGenerator, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(input_size, 2*512*8*8)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "        conv_padding_size = (kernel_size - 1) // 2\n",
        "\n",
        "        self.conv1 = nn.Conv2d(512, 2*256, kernel_size, padding=conv_padding_size)\n",
        "        self.conv2 = nn.Conv2d(256, 2*128, kernel_size, padding=conv_padding_size)\n",
        "        self.conv3 = nn.Conv2d(128, 1, kernel_size, padding=conv_padding_size)\n",
        "\n",
        "        self.activ_out = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.linear(x)\n",
        "        # GLU activation function\n",
        "        x, l = torch.split(x, x.shape[1]//2, 1)\n",
        "        x *= torch.sigmoid(l)\n",
        "        x = x.view((x.shape[0], 512, 8, 8))\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = self.conv1(x)\n",
        "        x, l = torch.split(x, x.shape[1]//2, 1)\n",
        "        x *= torch.sigmoid(l)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = self.conv2(x)\n",
        "        x, l = torch.split(x, x.shape[1]//2, 1)\n",
        "        x *= torch.sigmoid(l)\n",
        "\n",
        "        x = self.activ_out(self.conv3(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwsj5sRg0Mjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OTGANCritic(nn.Module):\n",
        "    def __init__(self, kernel_size=5):\n",
        "        super(OTGANCritic, self).__init__()\n",
        "\n",
        "        conv1_channels = 64\n",
        "        conv_padding_size = (kernel_size - 1) // 2\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, conv1_channels, kernel_size, padding=conv_padding_size)\n",
        "        self.conv2 = nn.Conv2d(conv1_channels*2, conv1_channels*2, kernel_size, \n",
        "                               stride=2, padding=conv_padding_size)\n",
        "        self.conv3 = nn.Conv2d(conv1_channels*4, conv1_channels*4, kernel_size, \n",
        "                               stride=2, padding=conv_padding_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # CReLU : https://github.com/pytorch/pytorch/issues/1327\n",
        "        x = torch.cat((F.relu(x), F.relu(-x)), 1)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.cat((F.relu(x), F.relu(-x)), 1)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.cat((F.relu(x), F.relu(-x)), 1)\n",
        "        x = nn.Flatten()(x)\n",
        "        x = F.normalize(x, dim=1, p=2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVnp5p-H0Wo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OTGAN():\n",
        "    \n",
        "    def __init__(self, dataloader, generator, critic, g_to_c_ratio=3, lr=0.0003):\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        # default parameters for mnist \n",
        "        self.img_channels = dataloader.dataset[0][0].shape[0]\n",
        "        self.img_rows = dataloader.dataset[0][0].shape[1]\n",
        "        self.img_cols = dataloader.dataset[0][0].shape[2]\n",
        "        self.img_shape = (self.img_channels, self.img_rows, self.img_cols)\n",
        "        self.z_dim = z_dim\n",
        "        self.lr = lr\n",
        "        self.g_to_c_ratio = g_to_c_ratio\n",
        "\n",
        "        self.generator = generator.to(device)\n",
        "        self.critic = critic.to(device)\n",
        "\n",
        "\n",
        "    def uniform_m1_1(self, size):\n",
        "        return -2 * torch.rand(size) + 1\n",
        "\n",
        "        \n",
        "    def sample_data(self, n_sample):\n",
        "        z_random = self.uniform_m1_1((n_sample, self.z_dim)).to(device)\n",
        "        samples = self.generator(z_random)\n",
        "        samples = samples.detach().cpu().numpy()\n",
        "        return samples\n",
        "\n",
        "\n",
        "    def cost(self, batch_1, batch_2):\n",
        "        dot = batch_1 @ batch_2.t()\n",
        "        norm1 = torch.norm(batch_1, 2, 1)\n",
        "        norm2 = torch.norm(batch_2, 2, 1)\n",
        "        div = torch.div(dot, norm1)\n",
        "        cos_sim = torch.div(div, torch.unsqueeze(norm2, 0))\n",
        "        return 1 - cos_sim\n",
        "\n",
        "    def sinkhorn(self, a, b, C, reg=1, max_iters=100):\n",
        "        \n",
        "        u = torch.ones_like(a).to(device)\n",
        "        v = torch.ones_like(b).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # No backprop through sinkhorn algorithm\n",
        "            K = torch.exp(-C/reg)\n",
        "            for i in range(max_iters):\n",
        "                u = a / (torch.matmul(K,v) + 1e-8)\n",
        "                v = b / (torch.matmul(K.T,u) + 1e-8)\n",
        "\n",
        "        return torch.matmul(torch.diag(u), \n",
        "                            torch.matmul(K, torch.diag(v)))\n",
        "\n",
        "        \n",
        "    def train(self, epochs=100, print_interval=10, save_every=1):\n",
        "        \n",
        "        c_optimizer = optim.Adam(self.critic.parameters(), lr=self.lr, \n",
        "                                 betas=(0.5, 0.999))\n",
        "        g_optimizer = optim.Adam(self.generator.parameters(), lr=self.lr, \n",
        "                                 betas=(0.5, 0.999))\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            t=time()\n",
        "            loss_to_display = []\n",
        "            \n",
        "            for i, (real_1, real_2) in enumerate(self.dataloader):\n",
        "                \n",
        "                batch_size = real_1.shape[0]\n",
        "\n",
        "                self.critic.zero_grad()\n",
        "                self.generator.zero_grad()\n",
        "    \n",
        "                real_1 = real_1.type(torch.FloatTensor).to(device)\n",
        "                real_2 = real_2.type(torch.FloatTensor).to(device)\n",
        "                \n",
        "                z1 = self.uniform_m1_1((batch_size, self.z_dim)).to(device)\n",
        "                fake_1 = self.generator(z1)\n",
        "                z2 = self.uniform_m1_1((batch_size, self.z_dim)).to(device)\n",
        "                fake_2 = self.generator(z2)\n",
        "                \n",
        "                critic_real_1 = self.critic(real_1)\n",
        "                critic_real_2 = self.critic(real_2)\n",
        "                critic_fake_1 = self.critic(fake_1)\n",
        "                critic_fake_2 = self.critic(fake_2)\n",
        "\n",
        "                # Computing all matrices of costs\n",
        "\n",
        "                costs = torch.zeros((4, 4, batch_size, batch_size)).to(device)\n",
        "\n",
        "                costs[0,1] = self.cost(critic_real_1, critic_real_2)\n",
        "                costs[0,2] = self.cost(critic_real_1, critic_fake_1)\n",
        "                costs[0,3] = self.cost(critic_real_1, critic_fake_2)\n",
        "                costs[1,2] = self.cost(critic_real_2, critic_fake_1)\n",
        "                costs[1,3] = self.cost(critic_real_2, critic_fake_2)\n",
        "                costs[2,3] = self.cost(critic_fake_1, critic_fake_2)\n",
        "\n",
        "                # Computing optimal plans for all costs\n",
        "\n",
        "                a = (torch.ones(batch_size) / batch_size).to(device)\n",
        "                b = (torch.ones(batch_size) / batch_size).to(device)\n",
        "                \n",
        "                plans = torch.zeros((4,4, batch_size, batch_size)).to(device)\n",
        "                plans[0,1] = self.sinkhorn(a, b, costs[0,1])\n",
        "                plans[0,2] = self.sinkhorn(a, b, costs[0,2])\n",
        "                plans[0,3] = self.sinkhorn(a, b, costs[0,3])\n",
        "                plans[1,2] = self.sinkhorn(a, b, costs[1,2])\n",
        "                plans[1,3] = self.sinkhorn(a, b, costs[1,3])\n",
        "                plans[2,3] = self.sinkhorn(a, b, costs[2,3]) \n",
        "\n",
        "                # Computing losses\n",
        "                \n",
        "                losses = torch.zeros((4,4)).to(device)\n",
        "                \n",
        "                losses[0,1] = torch.sum(plans[0,1] * costs[0,1])\n",
        "                losses[0,2] = torch.sum(plans[0,2] * costs[0,2])\n",
        "                losses[0,3] = torch.sum(plans[0,3] * costs[0,3])\n",
        "                losses[1,2] = torch.sum(plans[1,2] * costs[1,2])\n",
        "                losses[1,3] = torch.sum(plans[1,3] * costs[1,3])\n",
        "                losses[2,3] = torch.sum(plans[2,3] * costs[2,3])    \n",
        "                \n",
        "                loss = (losses[0,2] + losses[0,3] + losses[1,2] + losses[1,3] -\n",
        "                        2 * losses[0,1] - 2 * losses[2,3])\n",
        "                                \n",
        "                loss.backward()\n",
        "                g_optimizer.step()\n",
        "\n",
        "                if i+1 % self.g_to_c_ratio == 0:\n",
        "                    # Update critic once every `g_to_c_ratio` updates\n",
        "                    c_optimizer.step()\n",
        "                else:\n",
        "                    g_optimizer.step()\n",
        "\n",
        "                print(i)\n",
        "\n",
        "    \n",
        "            if epoch % print_interval == 0 or epoch+1 == epochs:\n",
        "                train_loss = loss.detach().cpu().numpy()\n",
        "                print(\"Epoch %s: loss = %s;  time = %s\" %\n",
        "                      (epoch, train_loss, time()-t))\n",
        "                \n",
        "            if epoch % print_interval == 0 or epoch+1 == epochs:\n",
        "                samples = self.sample_data(3)*0.5 + 0.5\n",
        "                for img in samples:\n",
        "                    plt.figure()\n",
        "                    plt.imshow(img[0,:,:], cmap='gray')\n",
        "                    plt.show()\n",
        "\n",
        "            if save_every:\n",
        "                torch.save(self.generator.state_dict(), 'ot_gan_gen.pt')\n",
        "                torch.save(self.critic.state_dict(), 'ot_gan_critic.pt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OvQ1f5EgKLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MNIST data as Torch dataloader\n",
        "img_size = 32\n",
        "batch_size = 512\n",
        "\n",
        "mnist_dataloader = load_mnist(batch_size=batch_size, img_size=img_size, \n",
        "                              double_batch=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCYPdlWa1LHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OT-GAN parameters\n",
        "z_dim = 100\n",
        "n_epochs = 10\n",
        "\n",
        "path_weights_otgan = 'ot_gan_gen.pt', 'ot_gan_critic.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxKfKV8oTsxh",
        "colab_type": "code",
        "outputId": "86860532-9832-433a-b5d9-24d2785d93ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TRAIN_MODE = True\n",
        "RESUME_TRAINING = False\n",
        "\n",
        "if TRAIN_MODE:\n",
        "    # Train GAN and save generator weights\n",
        "    otgan_generator = OTGANGenerator(input_size=z_dim)\n",
        "    otgan_critic = OTGANCritic()\n",
        "    otgan = OTGAN(mnist_dataloader, otgan_generator, otgan_critic)\n",
        "    otgan.train(n_epochs, save_every=1)\n",
        "else:\n",
        "    # Load previously trained model weights\n",
        "    otgan_generator = OTGANGenerator(input_size=z_dim)\n",
        "    otgan_generator.load_state_dict(torch.load(path_weights_otgan[0]))\n",
        "    otgan_critic = OTGANCritic()\n",
        "    otgan_critic.load_state_dict(torch.load(path_weights_otgan[1]))\n",
        "    otgan = OTGAN(mnist_dataloader, otgan_generator, otgan_critic, lr=lr)\n",
        "\n",
        "    if RESUME_TRAINING:\n",
        "        otgan.train(n_epochs, save_every=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "Epoch 0: loss = 0.003790915;  time = 1604.1197304725647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATIUlEQVR4nO3de4zW1Z3H8fd3mOEiIAgIThFBWHADvQCOxo2Xdm3aYCPSmo2p1tU/TKmbkq5JN8a4ydbd1MRutpompjV4SW3jtrBbGjUxKl4Sdv/RoktBUSnXChlAi8jgZXDgu388P5KB/L5nZp7rDOfzSgjPnO/8nufkN/OZ3zO/M+ccc3dE5MzX1uoOiEhzKOwimVDYRTKhsItkQmEXyYTCLpKJ9loONrNlwM+AUcAj7n7fAJ/vZlZa0xCgSH24e2nIrNqQmdkoYBvwNWAv8AfgRnffGh3T1tbmY8aMKa319vaGr6UfBCKnam8vv0739fWFYa/lbfylwHZ33+nux4DfAitqeD4RaaBawj4TeLffx3uLNhEZhmr6nX0wzGwlsLLRryMiabWEfR8wq9/H5xdtp3D31cBqqPzOXsPriUgNankb/wdgvpldaGajgW8DT9WnWyJSb1Vf2d29z8xWAc9RGXp7zN3fHOCY8K677riLDF5fX9+Qj6l66K0aGmcXabxGDL2JyAiisItkQmEXyYTCLpIJhV0kEw3/C7rT6a67SGvoyi6SCYVdJBMKu0gmFHaRTCjsIplo+t14qV00vyBVq3YURKMnZw5d2UUyobCLZEJhF8mEwi6SCYVdJBMKu0gmNPTWQqkhtLFjx4a1qVOnhrXJkyeXtqeG0I4ePRrWDh06FNY++eSTsFbNGmnSWLqyi2RCYRfJhMIukgmFXSQTCrtIJhR2kUzUNPRmZruBHuA40OfuXfXo1JkkNbyWGkJbvnx5VbW5c+eWto8aNSo8Zu/evWFtzZo1YW39+vVhrbu7u7T9xIkT4THSWPUYZ/9bd3+/Ds8jIg2kt/Eimag17A48b2avmdnKenRIRBqj1rfxV7j7PjObDqw3s7fdfUP/Tyh+COgHgUiL1XRld/d9xf8Hgd8Dl5Z8zmp379LNO5HWqjrsZjbezCaefAx8HXijXh0Tkfqq5W38DOD3xdBSO/Cf7v5sXXp1Bhk3blxYu+aaa8La7bffHtYWLFgQ1iZMmFDafvz48fCYtrb4Z35HR0dYSz2nDD9Vh93ddwJfqmNfRKSBNPQmkgmFXSQTCrtIJhR2kUwo7CKZ0IKTddDeHp/G+fPnh7UVK1aEtQsvvDCsTZw4MaxFw2j79+8Pj3nooYfC2tq1a8NaT09PWNPstuFHV3aRTCjsIplQ2EUyobCLZEJhF8mE7sYPQbSeXGotuWXLloW1RYsWhbVoQguk15M7fPhwafv9998fHvPII4+EtdQWTzKy6MoukgmFXSQTCrtIJhR2kUwo7CKZUNhFMqGht9OktmuKJqBcffXV4TGpobcZM2aEtdGjR4e1Y8eOhbVnnnmmtP3hhx8OjxkJw2up4cbURKToXLl7zX0aaXRlF8mEwi6SCYVdJBMKu0gmFHaRTCjsIpkYcOjNzB4DrgUOuvvni7YpwBpgDrAbuMHdP2hcN5vnrLPOCmtf/vKXS9tvuumm8JiLLroorI0fPz6spYaGuru7w9oDDzxQ2v7RRx+FxwwXqWHPK6+8MqzdcsstYW3Lli2l7T//+c/DY3p7e8PaSDaYK/svgdMHi+8CXnT3+cCLxcciMowNGPZiv/VDpzWvAB4vHj8OfLPO/RKROqv2d/YZ7n7yveR+Kju6isgwVvOfy7q7m1n4C6aZrQRW1vo6IlKbaq/sB8ysE6D4/2D0ie6+2t273L2rytcSkTqoNuxPAbcWj28FnqxPd0SkUQYz9PYb4CvANDPbC/wIuA9Ya2a3AXuAGxrZyXrr6OgIa1/4whfC2u23317a3tUVv2mZNGlSWEvN5Dp69GhYe/LJ+Gfr1q1bS9tHwiyvzs7OsHbvvfeGtaVLl4a1a6+9trR906ZN4TEvv/xyWBvJBgy7u98YlL5a576ISAPpL+hEMqGwi2RCYRfJhMIukgmFXSQTZ+yCk6kZVKnZZsuXLw9rl1xySWn7lClTqurHZ599FtbefffdsLZu3bqwNtxnbI0bNy6s3XnnnWEtNSQ6duzYsBad4+nTp4fHpL5mI2EIM6Iru0gmFHaRTCjsIplQ2EUyobCLZEJhF8nEGTv0lpKabZbafy0aNko9X19fX1j7y1/+EtY2bNgQ1nbu3BnWhotoeHPVqlXhMTfffPOQnw/g+PHjYe3DDz8sbd+/f394zJlKV3aRTCjsIplQ2EUyobCLZEJhF8nEGXs3PjVh4eOPPw5rb7/9dliL1oUbM2ZMeExq26UdO3aEtddffz2spSbQpEYGqtHeHn+LzJo1K6z94Ac/KG2/8cZolTOYOnVqWEvdcf/kk0/C2oEDB0rbUyMhI3myS4qu7CKZUNhFMqGwi2RCYRfJhMIukgmFXSQTg9n+6THgWuCgu3++aLsH+C7wXvFpd7v7M43qZL19+umnYe3pp58OaxdffHFp+5IlS8Jjjhw5EtZSWxClhobOPvvssBZJrat27rnnhrXLLrssrH3nO98Ja9GWTBMmTAiPSUkNr6XO1bZt24b8fDmvQfdLYFlJ+wPuvrj4N2KCLpKrAcPu7huAQ03oi4g0UC2/s68ys81m9piZnVO3HolIQ1Qb9l8A84DFQDfw0+gTzWylmW00s41VvpaI1EFVYXf3A+5+3N1PAA8DlyY+d7W7d7l7vIm5iDRcVWE3s85+H34LeKM+3RGRRhnM0NtvgK8A08xsL/Aj4CtmthhwYDfwvQb2se5Swye7du0Kaw8++GBp+3XXXRcek5oRt3fv3rCW2ibpoosuGvJxM2fODI+5/PLLw9rixYvD2uc+97mwFm3JlFqTLzUb8eDBg2EtNXtw69atYS3S1hZfA1Oz74a7AcPu7mVzEh9tQF9EpIH0F3QimVDYRTKhsItkQmEXyYTCLpKJM3bByWqlFnPcvHlzaXtHR0d4TDXDZJBezDE1S23u3Lml7fPmzQuPOf/888NaapZaanZYT09Pafv7778fHvPnP/85rL3zzjthbfv27WEtGt5MbSeVqkWLjgKcOHEirA0HurKLZEJhF8mEwi6SCYVdJBMKu0gmFHaRTDR96C0arhkuC/ml+hEtUpgaMpo+fXpYmzFjRliLhtAgPYx2wQUXlLZPmTIlPCaaoTaQ1D520TlJzULbsmVLWNu9e3dYSy3qGe19N2fOnPCYyZMnh7U9e/aEte7u7rCWGtKt5nu/mhzpyi6SCYVdJBMKu0gmFHaRTCjsIpnQ3fg6SK2rFt0NBjjvvPPCWuqOezV3klOTblJ6e3vDWmrbpWjiSuqOe2otuUOH4n1KUhNyOjs7S9tT5zAa0RjotV566aWw9txzz4W1Dz74YMivFeUl9b2oK7tIJhR2kUwo7CKZUNhFMqGwi2RCYRfJxGC2f5oF/AqYQWW7p9Xu/jMzmwKsAeZQ2QLqBncvH0M49flq6W9LRcNoqXXaUsNrs2fPDmuprZUmTZoU1kaPHl3anhraTG1plNqSKTX09t5775W2pybPpKQm60ycODGsRWsALl26dMjHQPrcp7bKSnnhhRdK248dOxYeEw2Jpr6Wg7my9wE/dPeFwGXA981sIXAX8KK7zwdeLD4WkWFqwLC7e7e7v1487gHeAmYCK4DHi097HPhmozopIrUb0u/sZjYHWAK8Asxw95MTePdTeZsvIsPUoP9c1swmAL8D7nD3I/1/93Z3N7PSXwrNbCWwstaOikhtBnVlN7MOKkF/wt3XFc0HzKyzqHcCpRtou/tqd+9y9656dFhEqjNg2K1yCX8UeMvd7+9Xegq4tXh8K/Bk/bsnIvUymLfxlwN/D2wxs01F293AfcBaM7sN2APcMNATmRltbeU/X1JDBs0U9Q/i4Z/U9kmpteRmzpwZ1lLroI0ZMyasRf1PbU2UWh8tWndvoOPOOuus0vZoFhqkhzBTswdTz7lo0aLS9tTXZerUqWEtGtqE9LBce3sctehrk/qaVbPV1IBhd/f/BaLB8a8O+RVFpCX0F3QimVDYRTKhsItkQmEXyYTCLpKJpi84Galmcb1m9yMaPkkNC3V0dIS11DBO6rjU60VS5zC1SGGqlup/NByZms2XGvZMzWxLbW0V1caPHx8ekzr3qeHGbdu2hbVXX301rB0+fLi0PfU1q2a4Tld2kUwo7CKZUNhFMqGwi2RCYRfJhMIukommDr25ezicMFz2eksNXRw5cqS0fePGjeExqUUDU0NNV111VVhLDV9Fw0bVznpLDb2lhqiimWOphSNTs95StdQ+dqnZZpHU+di/f39YW7NmTVjbtWtXWEt9j9STruwimVDYRTKhsItkQmEXyYTCLpIJa/IkE69mjbSRLHXHPXWHeeHChWHt+uuvD2tLliwpbU9NFvn000/DWrSNE6TXp4vu1J9zzjnhMam15KZNmxbWUnfjo0lDqTvghw4dCmvPPvtsWPvxj38c1rq7u8NavTPo7qWzuXRlF8mEwi6SCYVdJBMKu0gmFHaRTCjsIpkYcOjNzGYBv6KyJbMDq939Z2Z2D/Bd4OTYzN3u/swAz+XRGm/DZSLMSJCa3BFtQZTaairaqgnSw2u9vb1hLZKaCDNr1qywtmDBgrA2e/bssBatXdfT0xMek1pL7vnnnw9rO3bsCGvN3N4sGnobzJSgPuCH7v66mU0EXjOz9UXtAXf/j3p1UkQaZzB7vXUD3cXjHjN7C4gvEyIyLA3pd3YzmwMsAV4pmlaZ2WYze8zM4j+NEpGWG3TYzWwC8DvgDnc/AvwCmAcspnLl/2lw3Eoz22hm8QoPItJwgwq7mXVQCfoT7r4OwN0PuPtxdz8BPAxcWnasu6929y5376pXp0Vk6AYMu1Vunz8KvOXu9/dr7z9r4VvAG/XvnojUy2CG3q4A/gfYApycmnY3cCOVt/AO7Aa+V9zMSz2XxtdaJLWtVaqWUu/h0lQ/UrMHU2vhRbXUFlqpNehSMwRT6/U1UzT01vQprk17MTmFwn6qHMOuv6ATyYTCLpIJhV0kEwq7SCYUdpFM6G68yBlGd+NFMqewi2RCYRfJhMIukgmFXSQTCrtIJhR2kUwo7CKZUNhFMqGwi2RCYRfJhMIukgmFXSQTCrtIJhR2kUwo7CKZUNhFMqGwi2RCYRfJxGD2ehtrZq+a2R/N7E0z+9ei/UIze8XMtpvZGjMb3fjuighUds8p+5cymCt7L3C1u3+Jyt5uy8zsMuAnwAPu/lfAB8BtNfZfRBpowLB7xdHiw47inwNXA/9dtD8OfLMhPRSRuhjs/uyjzGwTcBBYD+wADrv7yZ3s9gIzG9NFEamHQYXd3Y+7+2LgfOBS4K8H+wJmttLMNprZxir7KCJ1MKS78e5+GHgZ+Btgspm1F6XzgX3BMavdvcvdu2rqqYjUZDB34881s8nF43HA14C3qIT+74pPuxV4slGdFJHaDbj9k5l9kcoNuFFUfjisdfd/M7O5wG+BKcD/ATe7e2/qudra2ry9vb20ltrIvplbVImkDDS8FUl9D0fP2dYWX4s7OjpK23t7ezlx4kTpEzZ1rzeFXUa6kRx2/QWdSCYUdpFMKOwimVDYRTKhsItkoql3483sPWBP8eE04P2mvXhM/TiV+nGqkdaP2e5+blmhqWE/5YXNNg6Hv6pTP9SPXPqht/EimVDYRTLRyrCvbuFr96d+nEr9ONUZ04+W/c4uIs2lt/EimWhJ2M1smZm9UyxWeVcr+lD0Y7eZbTGzTc1cXMPMHjOzg2b2Rr+2KWa23sz+VPx/Tov6cY+Z7SvOySYz+0YT+jHLzF42s63Foqb/WLQ39Zwk+tHUc9KwRV7dvan/qEyV3QHMBUYDfwQWNrsfRV92A9Na8LpXAUuBN/q1/TtwV/H4LuAnLerHPcA/Nfl8dAJLi8cTgW3Awmafk0Q/mnpOAAMmFI87gFeAy4C1wLeL9oeAfxjK87biyn4psN3dd7r7MSpz4le0oB8t4+4bgEOnNa+gsm4ANGkBz6AfTefu3e7+evG4h8riKDNp8jlJ9KOpvKLui7y2IuwzgXf7fdzKxSodeN7MXjOzlS3qw0kz3L27eLwfmNHCvqwys83F2/yG/zrRn5nNAZZQuZq17Jyc1g9o8jlpxCKvud+gu8LdlwLXAN83s6ta3SGo/GSn8oOoFX4BzKOyR0A38NNmvbCZTQB+B9zh7kf615p5Tkr60fRz4jUs8hppRdj3AbP6fRwuVtlo7r6v+P8g8HsqJ7VVDphZJ0Dx/8FWdMLdDxTfaCeAh2nSOTGzDioBe8Ld1xXNTT8nZf1o1TkpXnvIi7xGWhH2PwDzizuLo4FvA081uxNmNt7MJp58DHwdeCN9VEM9RWXhTmjhAp4nw1X4Fk04J1ZZl+lR4C13v79fqannJOpHs89JwxZ5bdYdxtPuNn6Dyp3OHcA/t6gPc6mMBPwReLOZ/QB+Q+Xt4GdUfve6DZgKvAj8CXgBmNKifvwa2AJsphK2zib04woqb9E3A5uKf99o9jlJ9KOp5wT4IpVFXDdT+cHyL/2+Z18FtgP/BYwZyvPqL+hEMpH7DTqRbCjsIplQ2EUyobCLZEJhF8mEwi6SCYVdJBMKu0gm/h9OdrGu6QVl1AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oraWezOSFwDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "e8de5791-fc05-4434-dd60-1345075532f6"
      },
      "source": [
        "# Plot some generated images as a GIF\n",
        "samples = otgan.sample_data(100)*0.5 + 0.5\n",
        "samples = samples * 256\n",
        "samples = samples.astype(np.uint8)\n",
        "samples = np.squeeze(samples, 1)\n",
        "\n",
        "gif_path = 'otgan_gan.gif'\n",
        "imageio.mimwrite(gif_path, samples, fps=5)\n",
        "gifPath = Path(gif_path)\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png', width=200, height=200)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 200,
              "height": 200
            }
          },
          "execution_count": 22
        }
      ]
    }
  ]
}